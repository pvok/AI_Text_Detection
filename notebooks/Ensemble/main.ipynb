{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gehna\\Documents\\MSCS\\Sem2\\Deep_Learning\\Ensemble_model\\ensemble_dl\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import contractions\n",
    "\n",
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(mode):\n",
    "    if mode == 0:\n",
    "        text = input()\n",
    "        label = input()\n",
    "        df = pd.DataFrame({'text': text, 'truth_label': label}, index=range(len(label)))\n",
    "        return df\n",
    "    elif mode == 1:\n",
    "        df = pd.read_csv('trail.csv')\n",
    "        return df\n",
    "    else:\n",
    "        return print(\"Please Enter valid mode that is either 0 or 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(df , model_path, model_tokenizer, max_len):\n",
    "\n",
    "    with open(model_tokenizer, \"rb\") as file:\n",
    "        tokenizer = pickle.load(file)\n",
    "\n",
    "    cnn_model = load_model(model_path)\n",
    "\n",
    "    txt_test = df['text'].astype(str).values\n",
    "    token_test = tokenizer.texts_to_sequences(txt_test)\n",
    "    pad_token_test = pad_sequences(token_test, padding='post', maxlen=max_len)\n",
    "\n",
    "    pred = cnn_model.predict(pad_token_test)\n",
    "    preds_lbl = np.where(pred > 0.5,1,0)\n",
    "\n",
    "    return preds_lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roberta_model(df , model_path, model_tokenizer , max_len):\n",
    "\n",
    "    df['sentences'] = df['text'].str.lower()\n",
    "    df['sentences'] = df['sentences'].apply(lambda x: contractions.fix(x))\n",
    "    df['sentences'] = df['sentences'].apply(lambda x: x.split('.'))\n",
    "    # df_roberta = data_prep(df)\n",
    "    checkpoint_path = model_path\n",
    "\n",
    "    # Load the checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path , map_location=torch.device('cpu'))\n",
    "\n",
    "    # Extract the state dictionary that corresponds to the model\n",
    "    model_state_dict = checkpoint['model_state_dict']\n",
    "\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(model_tokenizer)\n",
    "    # Initialize the model\n",
    "    model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)\n",
    "\n",
    "    # Load the state dictionary into the model\n",
    "    model.load_state_dict(model_state_dict)\n",
    "    model.eval()\n",
    "    model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "    def prepare_data(texts, tokenizer, max_length=max_len):\n",
    "        encoding = tokenizer(texts, truncation=True, padding=\"max_length\", max_length=max_length, return_tensors=\"pt\")\n",
    "        return encoding\n",
    "    \n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "\n",
    "    # Iterate over sampled data to predict and collect probabilities\n",
    "    for index, row in df.iterrows():\n",
    "        encoded_input = prepare_data(row['sentences'], tokenizer)\n",
    "        encoded_input = {key: value.to(model.device) for key, value in encoded_input.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encoded_input)\n",
    "            probs = torch.nn.functional.softmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "            predictions.append(probs.argmax(axis=-1)[0])\n",
    "            probabilities.append(probs[0, 1])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_model(df, model_and_tokenizer_path , max_len):\n",
    "\n",
    "    df['sentences'] = df['text'].str.lower()\n",
    "    df['sentences'] = df['sentences'].apply(lambda x: contractions.fix(x))\n",
    "    df['sentences'] = df['sentences'].apply(lambda x: x.split('.'))\n",
    "\n",
    "    model_path = model_and_tokenizer_path  # Adjust to where your model is saved\n",
    "    model = GPT2ForSequenceClassification.from_pretrained(model_path)\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
    "    model.eval()\n",
    "\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    prediction = []\n",
    "    probability = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        input_ids = tokenizer(row['sentences'], truncation=True, padding=\"max_length\", max_length=max_len, return_tensors=\"pt\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**input_ids)\n",
    "            probs = torch.nn.functional.softmax(outputs.logits, dim=-1).numpy()\n",
    "            prediction.append(probs.argmax(axis=-1)[0])\n",
    "            probability.append(probs[0, 1])\n",
    "            \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "pred_cnn = cnn_model(df,model_path=r'models_and_tokenizers\\cnn\\cnn_50k.keras', model_tokenizer=r'models_and_tokenizers\\cnn\\tokenizer_cnn.pickle', max_len = 1000)\n",
    "pred_roberta = roberta_model(df , model_path = r'models_and_tokenizers\\roberta\\checkpoint_epoch_3_roberta.pth', model_tokenizer = r'models_and_tokenizers\\roberta', max_len = 512)\n",
    "pred_gpt = gpt_model(df , model_and_tokenizer_path = r'models_and_tokenizers\\gpt_2', max_len = 512 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human : 0, LLM : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 0, 1, 0, 0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 1, 0, 0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = []\n",
    "for i in range(len(pred_gpt)):\n",
    "    lst = [pred_cnn[i][0],pred_roberta[i],pred_gpt[i]]\n",
    "    final_pred.append(max(lst, key=lst.count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    1\n",
       "5    1\n",
       "6    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 0, 1, 0, 0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_final = accuracy_score(df['label'].values, final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
