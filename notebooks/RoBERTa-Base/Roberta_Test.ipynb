{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load test data\n",
    "sampled_df = pd.read_csv(r'C:\\Users\\sagar\\OneDrive\\Desktop\\Sem 3\\Deep Learning\\Project Roberta\\to_Transformer_Train2.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Sample a subset of data for testing to reduce computation\n",
    "sampled_df = test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>label</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm not happy with what I've wrote to be hones...</td>\n",
       "      <td>Human</td>\n",
       "      <td>0</td>\n",
       "      <td>['i am not happy with what i have wrote to be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Postmodernist Anthropology and its Impact on T...</td>\n",
       "      <td>Human</td>\n",
       "      <td>0</td>\n",
       "      <td>['postmodernist anthropology and its impact on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Firstly, is it okay to write an essay or does ...</td>\n",
       "      <td>Human</td>\n",
       "      <td>0</td>\n",
       "      <td>['firstly, is it okay to write an essay or doe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Nissan Company’s Operational Changes and Manag...</td>\n",
       "      <td>Human</td>\n",
       "      <td>0</td>\n",
       "      <td>['nissan company’s operational changes and man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>I think some people might find visiting a nati...</td>\n",
       "      <td>Human</td>\n",
       "      <td>0</td>\n",
       "      <td>['i think some people might find visiting a na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>49995</td>\n",
       "      <td>49995</td>\n",
       "      <td>The exploration of space has always captivated...</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>['the exploration of space has always captivat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>49996</td>\n",
       "      <td>49996</td>\n",
       "      <td>Famous people, whether they are actors, athlet...</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>['famous people, whether they are actors, athl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>49997</td>\n",
       "      <td>49997</td>\n",
       "      <td>The future of 3D printing and its applications...</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>['the future of 3d printing and its applicatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>49998</td>\n",
       "      <td>49998</td>\n",
       "      <td>The world is currently facing a critical issue...</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>['the world is currently facing a critical iss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>49999</td>\n",
       "      <td>49999</td>\n",
       "      <td>Native American medicine bags hold a significa...</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>['native american medicine bags hold a signifi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.1  Unnamed: 0  \\\n",
       "0                 0           0   \n",
       "1                 1           1   \n",
       "2                 2           2   \n",
       "3                 3           3   \n",
       "4                 4           4   \n",
       "...             ...         ...   \n",
       "49995         49995       49995   \n",
       "49996         49996       49996   \n",
       "49997         49997       49997   \n",
       "49998         49998       49998   \n",
       "49999         49999       49999   \n",
       "\n",
       "                                                    text   source  label  \\\n",
       "0      I'm not happy with what I've wrote to be hones...    Human      0   \n",
       "1      Postmodernist Anthropology and its Impact on T...    Human      0   \n",
       "2      Firstly, is it okay to write an essay or does ...    Human      0   \n",
       "3      Nissan Company’s Operational Changes and Manag...    Human      0   \n",
       "4      I think some people might find visiting a nati...    Human      0   \n",
       "...                                                  ...      ...    ...   \n",
       "49995  The exploration of space has always captivated...  GPT-3.5      1   \n",
       "49996  Famous people, whether they are actors, athlet...  GPT-3.5      1   \n",
       "49997  The future of 3D printing and its applications...  GPT-3.5      1   \n",
       "49998  The world is currently facing a critical issue...  GPT-3.5      1   \n",
       "49999  Native American medicine bags hold a significa...  GPT-3.5      1   \n",
       "\n",
       "                                               sentences  \n",
       "0      ['i am not happy with what i have wrote to be ...  \n",
       "1      ['postmodernist anthropology and its impact on...  \n",
       "2      ['firstly, is it okay to write an essay or doe...  \n",
       "3      ['nissan company’s operational changes and man...  \n",
       "4      ['i think some people might find visiting a na...  \n",
       "...                                                  ...  \n",
       "49995  ['the exploration of space has always captivat...  \n",
       "49996  ['famous people, whether they are actors, athl...  \n",
       "49997  ['the future of 3d printing and its applicatio...  \n",
       "49998  ['the world is currently facing a critical iss...  \n",
       "49999  ['native american medicine bags hold a signifi...  \n",
       "\n",
       "[50000 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import contractions\n",
    "# Lowercase conversion\n",
    "sampled_df['sentences'] = sampled_df['text'].str.lower()\n",
    "\n",
    "# Expanding contractions\n",
    "sampled_df['sentences'] = sampled_df['sentences'].apply(lambda x: contractions.fix(x))\n",
    "\n",
    "# Tokenization\n",
    "\n",
    "##Sentence_length_calculation\n",
    "sampled_df['sentences'] = sampled_df['sentences'].apply(lambda x: x.split('.'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sampled_df.to_csv('to_Transformer_Train2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torch\n",
    "# from transformers import RobertaForSequenceClassification\n",
    "\n",
    "# Path to your saved model checkpoint\n",
    "checkpoint_path = './model_checkpoints_Roberta_Venkat/checkpoint_epoch_3.pth'\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "# Extract the state dictionary that corresponds to the model\n",
    "model_state_dict = checkpoint['model_state_dict']\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('./model_checkpoints_finetune')\n",
    "# Initialize the model\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(model_state_dict)\n",
    "model.eval()\n",
    "model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the tokenizer and model\n",
    "# model_path = './model_checkpoints'  # Adjust to where your model checkpoint is saved\n",
    "# tokenizer = RobertaTokenizer.from_pretrained(model_path)\n",
    "# model = RobertaForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
    "# model.eval()\n",
    "# model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Print out the parameter settings to verify\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name} is {'trainable' if param.requires_grad else 'frozen'}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Freeze all parameters first\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Set the last two layers of the encoder and the classifier to be trainable\n",
    "layer_indices = [10, 11]  # The last two layers\n",
    "\n",
    "for i, layer in enumerate(model.roberta.encoder.layer):\n",
    "    if i in layer_indices:\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "# Make classifier layer trainable\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Verify which parameters are trainable\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name} is {'trainable' if param.requires_grad else 'frozen'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the test dataset\n",
    "def prepare_data(texts, tokenizer, max_length=512):\n",
    "    encoding = tokenizer(texts, truncation=True, padding=\"max_length\", max_length=max_length, return_tensors=\"pt\")\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predictions = []\n",
    "probabilities = []\n",
    "\n",
    "# Iterate over sampled data to predict and collect probabilities\n",
    "for index, row in sampled_df.iterrows():\n",
    "    encoded_input = prepare_data(row['sentences'], tokenizer)\n",
    "    encoded_input = {key: value.to(model.device) for key, value in encoded_input.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoded_input)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "        predictions.append(probs.argmax(axis=-1)[0])\n",
    "        probabilities.append(probs[0, 1])  # Storing the probability of the positive class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [12:54, 64.52it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "predictions = []\n",
    "probabilities = []\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for index, row in tqdm(sampled_df.iterrows()):\n",
    "    input_ids = tokenizer(row['sentences'], truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\")\n",
    "    \n",
    "    # Move input_ids tensor to the same device as the model\n",
    "    input_ids = {key: value.to(device) for key, value in input_ids.items()}\n",
    "\n",
    "    true_label = torch.tensor(row['label']).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**input_ids)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Move logits tensor to CPU and then convert it to a NumPy array\n",
    "        logits_cpu = logits.to('cpu')\n",
    "        probs = torch.nn.functional.softmax(logits_cpu, dim=-1).numpy()\n",
    "        \n",
    "        # Deallocate GPU memory\n",
    "        del logits, logits_cpu\n",
    "        \n",
    "        predictions.append(probs.argmax(axis=-1)[0])\n",
    "        probabilities.append(probs[0, 1])  # Storing the probability of the positive class\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store predictions and probabilities in the DataFrame\n",
    "sampled_df['predictions'] = predictions\n",
    "sampled_df['probabilities'] = probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9751\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy of the predictions\n",
    "actual_labels = sampled_df['label'].values\n",
    "accuracy = accuracy_score(actual_labels, predictions)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9751087282763387\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "f1score = f1_score(sampled_df['label'].values, sampled_df['predictions'], average='weighted')\n",
    "print(f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Cross-Entropy Loss: 0.8967660963212349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagar\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: Downcasting behavior in Series and DataFrame methods 'where', 'mask', and 'clip' is deprecated. In a future version this will not infer object dtypes or cast all-round floats to integers. Instead call result.infer_objects(copy=False) for object inference, or cast round floats explicitly. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return bound(*args, **kwds)\n",
      "C:\\Users\\sagar\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: Downcasting behavior in Series and DataFrame methods 'where', 'mask', and 'clip' is deprecated. In a future version this will not infer object dtypes or cast all-round floats to integers. Instead call result.infer_objects(copy=False) for object inference, or cast round floats explicitly. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "import numpy as np\n",
    "# Assuming test_df['predictions'] and test_df['label'] are NumPy arrays or lists\n",
    "predictions = sampled_df['predictions']  # Predicted probabilities\n",
    "labels = sampled_df['label']  # True labels\n",
    "\n",
    "# Ensure predictions are probabilities between 0 and 1\n",
    "predictions = np.clip(predictions, 1e-15, 1 - 1e-15)\n",
    "\n",
    "# Calculate binary cross-entropy loss\n",
    "binary_cross_entropy_loss = log_loss(labels, predictions)\n",
    "\n",
    "print(\"Binary Cross-Entropy Loss:\", binary_cross_entropy_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Compute and plot the ROC curve\n",
    "fpr, tpr, _ = roc_curve(actual_labels, probabilities)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import torch\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "# from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Load test data\n",
    "# test_df = pd.read_csv(\"V:\\\\deep_learning\\\\Project\\\\Test\\\\to_test.csv\")\n",
    "# sampled_df = test_df.sample(n=100, random_state=42)\n",
    "\n",
    "# # Load the tokenizer\n",
    "# tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# # Initialize the model with the correct configuration and number of labels\n",
    "# model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torch\n",
    "# from transformers import RobertaForSequenceClassification\n",
    "\n",
    "# # Path to your saved model checkpoint\n",
    "# checkpoint_path = './model_checkpoints/checkpoint_epoch_3.pth'\n",
    "\n",
    "# # Load the checkpoint\n",
    "# checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "# # Extract the state dictionary that corresponds to the model\n",
    "# model_state_dict = checkpoint['model_state_dict']\n",
    "\n",
    "# # Initialize the model\n",
    "# model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)\n",
    "\n",
    "# # Load the state dictionary into the model\n",
    "# model.load_state_dict(model_state_dict)\n",
    "# model.eval()\n",
    "# model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta.embeddings.word_embeddings.weight is trainable\n",
      "roberta.embeddings.position_embeddings.weight is trainable\n",
      "roberta.embeddings.token_type_embeddings.weight is trainable\n",
      "roberta.embeddings.LayerNorm.weight is trainable\n",
      "roberta.embeddings.LayerNorm.bias is trainable\n",
      "roberta.encoder.layer.0.attention.self.query.weight is trainable\n",
      "roberta.encoder.layer.0.attention.self.query.bias is trainable\n",
      "roberta.encoder.layer.0.attention.self.key.weight is trainable\n",
      "roberta.encoder.layer.0.attention.self.key.bias is trainable\n",
      "roberta.encoder.layer.0.attention.self.value.weight is trainable\n",
      "roberta.encoder.layer.0.attention.self.value.bias is trainable\n",
      "roberta.encoder.layer.0.attention.output.dense.weight is trainable\n",
      "roberta.encoder.layer.0.attention.output.dense.bias is trainable\n",
      "roberta.encoder.layer.0.attention.output.LayerNorm.weight is trainable\n",
      "roberta.encoder.layer.0.attention.output.LayerNorm.bias is trainable\n",
      "roberta.encoder.layer.0.intermediate.dense.weight is trainable\n",
      "roberta.encoder.layer.0.intermediate.dense.bias is trainable\n",
      "roberta.encoder.layer.0.output.dense.weight is trainable\n",
      "roberta.encoder.layer.0.output.dense.bias is trainable\n",
      "roberta.encoder.layer.0.output.LayerNorm.weight is trainable\n",
      "roberta.encoder.layer.0.output.LayerNorm.bias is trainable\n",
      "roberta.encoder.layer.1.attention.self.query.weight is trainable\n",
      "roberta.encoder.layer.1.attention.self.query.bias is trainable\n",
      "roberta.encoder.layer.1.attention.self.key.weight is trainable\n",
      "roberta.encoder.layer.1.attention.self.key.bias is trainable\n",
      "roberta.encoder.layer.1.attention.self.value.weight is trainable\n",
      "roberta.encoder.layer.1.attention.self.value.bias is trainable\n",
      "roberta.encoder.layer.1.attention.output.dense.weight is trainable\n",
      "roberta.encoder.layer.1.attention.output.dense.bias is trainable\n",
      "roberta.encoder.layer.1.attention.output.LayerNorm.weight is trainable\n",
      "roberta.encoder.layer.1.attention.output.LayerNorm.bias is trainable\n",
      "roberta.encoder.layer.1.intermediate.dense.weight is trainable\n",
      "roberta.encoder.layer.1.intermediate.dense.bias is trainable\n",
      "roberta.encoder.layer.1.output.dense.weight is trainable\n",
      "roberta.encoder.layer.1.output.dense.bias is trainable\n",
      "roberta.encoder.layer.1.output.LayerNorm.weight is trainable\n",
      "roberta.encoder.layer.1.output.LayerNorm.bias is trainable\n",
      "roberta.encoder.layer.2.attention.self.query.weight is trainable\n",
      "roberta.encoder.layer.2.attention.self.query.bias is trainable\n",
      "roberta.encoder.layer.2.attention.self.key.weight is trainable\n",
      "roberta.encoder.layer.2.attention.self.key.bias is trainable\n",
      "roberta.encoder.layer.2.attention.self.value.weight is trainable\n",
      "roberta.encoder.layer.2.attention.self.value.bias is trainable\n",
      "roberta.encoder.layer.2.attention.output.dense.weight is trainable\n",
      "roberta.encoder.layer.2.attention.output.dense.bias is trainable\n",
      "roberta.encoder.layer.2.attention.output.LayerNorm.weight is trainable\n",
      "roberta.encoder.layer.2.attention.output.LayerNorm.bias is trainable\n",
      "roberta.encoder.layer.2.intermediate.dense.weight is trainable\n",
      "roberta.encoder.layer.2.intermediate.dense.bias is trainable\n",
      "roberta.encoder.layer.2.output.dense.weight is trainable\n",
      "roberta.encoder.layer.2.output.dense.bias is trainable\n",
      "roberta.encoder.layer.2.output.LayerNorm.weight is trainable\n",
      "roberta.encoder.layer.2.output.LayerNorm.bias is trainable\n",
      "roberta.encoder.layer.3.attention.self.query.weight is trainable\n",
      "roberta.encoder.layer.3.attention.self.query.bias is trainable\n",
      "roberta.encoder.layer.3.attention.self.key.weight is trainable\n",
      "roberta.encoder.layer.3.attention.self.key.bias is trainable\n",
      "roberta.encoder.layer.3.attention.self.value.weight is trainable\n",
      "roberta.encoder.layer.3.attention.self.value.bias is trainable\n",
      "roberta.encoder.layer.3.attention.output.dense.weight is trainable\n",
      "roberta.encoder.layer.3.attention.output.dense.bias is trainable\n",
      "roberta.encoder.layer.3.attention.output.LayerNorm.weight is trainable\n",
      "roberta.encoder.layer.3.attention.output.LayerNorm.bias is trainable\n",
      "roberta.encoder.layer.3.intermediate.dense.weight is trainable\n",
      "roberta.encoder.layer.3.intermediate.dense.bias is trainable\n",
      "roberta.encoder.layer.3.output.dense.weight is trainable\n",
      "roberta.encoder.layer.3.output.dense.bias is trainable\n",
      "roberta.encoder.layer.3.output.LayerNorm.weight is trainable\n",
      "roberta.encoder.layer.3.output.LayerNorm.bias is trainable\n",
      "roberta.encoder.layer.4.attention.self.query.weight is trainable\n",
      "roberta.encoder.layer.4.attention.self.query.bias is trainable\n",
      "roberta.encoder.layer.4.attention.self.key.weight is trainable\n",
      "roberta.encoder.layer.4.attention.self.key.bias is trainable\n",
      "roberta.encoder.layer.4.attention.self.value.weight is trainable\n",
      "roberta.encoder.layer.4.attention.self.value.bias is trainable\n",
      "roberta.encoder.layer.4.attention.output.dense.weight is trainable\n",
      "roberta.encoder.layer.4.attention.output.dense.bias is trainable\n",
      "roberta.encoder.layer.4.attention.output.LayerNorm.weight is trainable\n",
      "roberta.encoder.layer.4.attention.output.LayerNorm.bias is trainable\n",
      "roberta.encoder.layer.4.intermediate.dense.weight is trainable\n",
      "roberta.encoder.layer.4.intermediate.dense.bias is trainable\n",
      "roberta.encoder.layer.4.output.dense.weight is trainable\n",
      "roberta.encoder.layer.4.output.dense.bias is trainable\n",
      "roberta.encoder.layer.4.output.LayerNorm.weight is trainable\n",
      "roberta.encoder.layer.4.output.LayerNorm.bias is trainable\n",
      "roberta.encoder.layer.5.attention.self.query.weight is trainable\n",
      "roberta.encoder.layer.5.attention.self.query.bias is trainable\n",
      "roberta.encoder.layer.5.attention.self.key.weight is trainable\n",
      "roberta.encoder.layer.5.attention.self.key.bias is trainable\n",
      "roberta.encoder.layer.5.attention.self.value.weight is trainable\n",
      "roberta.encoder.layer.5.attention.self.value.bias is trainable\n",
      "roberta.encoder.layer.5.attention.output.dense.weight is trainable\n",
      "roberta.encoder.layer.5.attention.output.dense.bias is trainable\n",
      "roberta.encoder.layer.5.attention.output.LayerNorm.weight is trainable\n",
      "roberta.encoder.layer.5.attention.output.LayerNorm.bias is trainable\n",
      "roberta.encoder.layer.5.intermediate.dense.weight is trainable\n",
      "roberta.encoder.layer.5.intermediate.dense.bias is trainable\n",
      "roberta.encoder.layer.5.output.dense.weight is trainable\n",
      "roberta.encoder.layer.5.output.dense.bias is trainable\n",
      "roberta.encoder.layer.5.output.LayerNorm.weight is trainable\n",
      "roberta.encoder.layer.5.output.LayerNorm.bias is trainable\n",
      "roberta.encoder.layer.6.attention.self.query.weight is trainable\n",
      "roberta.encoder.layer.6.attention.self.query.bias is trainable\n",
      "roberta.encoder.layer.6.attention.self.key.weight is trainable\n",
      "roberta.encoder.layer.6.attention.self.key.bias is trainable\n",
      "roberta.encoder.layer.6.attention.self.value.weight is trainable\n",
      "roberta.encoder.layer.6.attention.self.value.bias is trainable\n",
      "roberta.encoder.layer.6.attention.output.dense.weight is trainable\n",
      "roberta.encoder.layer.6.attention.output.dense.bias is trainable\n",
      "roberta.encoder.layer.6.attention.output.LayerNorm.weight is trainable\n",
      "roberta.encoder.layer.6.attention.output.LayerNorm.bias is trainable\n",
      "roberta.encoder.layer.6.intermediate.dense.weight is trainable\n",
      "roberta.encoder.layer.6.intermediate.dense.bias is trainable\n",
      "roberta.encoder.layer.6.output.dense.weight is trainable\n",
      "roberta.encoder.layer.6.output.dense.bias is trainable\n",
      "roberta.encoder.layer.6.output.LayerNorm.weight is trainable\n",
      "roberta.encoder.layer.6.output.LayerNorm.bias is trainable\n",
      "roberta.encoder.layer.7.attention.self.query.weight is trainable\n",
      "roberta.encoder.layer.7.attention.self.query.bias is trainable\n",
      "roberta.encoder.layer.7.attention.self.key.weight is trainable\n",
      "roberta.encoder.layer.7.attention.self.key.bias is trainable\n",
      "roberta.encoder.layer.7.attention.self.value.weight is trainable\n",
      "roberta.encoder.layer.7.attention.self.value.bias is trainable\n",
      "roberta.encoder.layer.7.attention.output.dense.weight is trainable\n",
      "roberta.encoder.layer.7.attention.output.dense.bias is trainable\n",
      "roberta.encoder.layer.7.attention.output.LayerNorm.weight is trainable\n",
      "roberta.encoder.layer.7.attention.output.LayerNorm.bias is trainable\n",
      "roberta.encoder.layer.7.intermediate.dense.weight is trainable\n",
      "roberta.encoder.layer.7.intermediate.dense.bias is trainable\n",
      "roberta.encoder.layer.7.output.dense.weight is trainable\n",
      "roberta.encoder.layer.7.output.dense.bias is trainable\n",
      "roberta.encoder.layer.7.output.LayerNorm.weight is trainable\n",
      "roberta.encoder.layer.7.output.LayerNorm.bias is trainable\n",
      "roberta.encoder.layer.8.attention.self.query.weight is trainable\n",
      "roberta.encoder.layer.8.attention.self.query.bias is trainable\n",
      "roberta.encoder.layer.8.attention.self.key.weight is trainable\n",
      "roberta.encoder.layer.8.attention.self.key.bias is trainable\n",
      "roberta.encoder.layer.8.attention.self.value.weight is trainable\n",
      "roberta.encoder.layer.8.attention.self.value.bias is trainable\n",
      "roberta.encoder.layer.8.attention.output.dense.weight is trainable\n",
      "roberta.encoder.layer.8.attention.output.dense.bias is trainable\n",
      "roberta.encoder.layer.8.attention.output.LayerNorm.weight is trainable\n",
      "roberta.encoder.layer.8.attention.output.LayerNorm.bias is trainable\n",
      "roberta.encoder.layer.8.intermediate.dense.weight is trainable\n",
      "roberta.encoder.layer.8.intermediate.dense.bias is trainable\n",
      "roberta.encoder.layer.8.output.dense.weight is trainable\n",
      "roberta.encoder.layer.8.output.dense.bias is trainable\n",
      "roberta.encoder.layer.8.output.LayerNorm.weight is trainable\n",
      "roberta.encoder.layer.8.output.LayerNorm.bias is trainable\n",
      "roberta.encoder.layer.9.attention.self.query.weight is trainable\n",
      "roberta.encoder.layer.9.attention.self.query.bias is trainable\n",
      "roberta.encoder.layer.9.attention.self.key.weight is trainable\n",
      "roberta.encoder.layer.9.attention.self.key.bias is trainable\n",
      "roberta.encoder.layer.9.attention.self.value.weight is trainable\n",
      "roberta.encoder.layer.9.attention.self.value.bias is trainable\n",
      "roberta.encoder.layer.9.attention.output.dense.weight is trainable\n",
      "roberta.encoder.layer.9.attention.output.dense.bias is trainable\n",
      "roberta.encoder.layer.9.attention.output.LayerNorm.weight is trainable\n",
      "roberta.encoder.layer.9.attention.output.LayerNorm.bias is trainable\n",
      "roberta.encoder.layer.9.intermediate.dense.weight is trainable\n",
      "roberta.encoder.layer.9.intermediate.dense.bias is trainable\n",
      "roberta.encoder.layer.9.output.dense.weight is trainable\n",
      "roberta.encoder.layer.9.output.dense.bias is trainable\n",
      "roberta.encoder.layer.9.output.LayerNorm.weight is trainable\n",
      "roberta.encoder.layer.9.output.LayerNorm.bias is trainable\n",
      "roberta.encoder.layer.10.attention.self.query.weight is trainable\n",
      "roberta.encoder.layer.10.attention.self.query.bias is trainable\n",
      "roberta.encoder.layer.10.attention.self.key.weight is trainable\n",
      "roberta.encoder.layer.10.attention.self.key.bias is trainable\n",
      "roberta.encoder.layer.10.attention.self.value.weight is trainable\n",
      "roberta.encoder.layer.10.attention.self.value.bias is trainable\n",
      "roberta.encoder.layer.10.attention.output.dense.weight is trainable\n",
      "roberta.encoder.layer.10.attention.output.dense.bias is trainable\n",
      "roberta.encoder.layer.10.attention.output.LayerNorm.weight is trainable\n",
      "roberta.encoder.layer.10.attention.output.LayerNorm.bias is trainable\n",
      "roberta.encoder.layer.10.intermediate.dense.weight is trainable\n",
      "roberta.encoder.layer.10.intermediate.dense.bias is trainable\n",
      "roberta.encoder.layer.10.output.dense.weight is trainable\n",
      "roberta.encoder.layer.10.output.dense.bias is trainable\n",
      "roberta.encoder.layer.10.output.LayerNorm.weight is trainable\n",
      "roberta.encoder.layer.10.output.LayerNorm.bias is trainable\n",
      "roberta.encoder.layer.11.attention.self.query.weight is trainable\n",
      "roberta.encoder.layer.11.attention.self.query.bias is trainable\n",
      "roberta.encoder.layer.11.attention.self.key.weight is trainable\n",
      "roberta.encoder.layer.11.attention.self.key.bias is trainable\n",
      "roberta.encoder.layer.11.attention.self.value.weight is trainable\n",
      "roberta.encoder.layer.11.attention.self.value.bias is trainable\n",
      "roberta.encoder.layer.11.attention.output.dense.weight is trainable\n",
      "roberta.encoder.layer.11.attention.output.dense.bias is trainable\n",
      "roberta.encoder.layer.11.attention.output.LayerNorm.weight is trainable\n",
      "roberta.encoder.layer.11.attention.output.LayerNorm.bias is trainable\n",
      "roberta.encoder.layer.11.intermediate.dense.weight is trainable\n",
      "roberta.encoder.layer.11.intermediate.dense.bias is trainable\n",
      "roberta.encoder.layer.11.output.dense.weight is trainable\n",
      "roberta.encoder.layer.11.output.dense.bias is trainable\n",
      "roberta.encoder.layer.11.output.LayerNorm.weight is trainable\n",
      "roberta.encoder.layer.11.output.LayerNorm.bias is trainable\n",
      "classifier.dense.weight is trainable\n",
      "classifier.dense.bias is trainable\n",
      "classifier.out_proj.weight is trainable\n",
      "classifier.out_proj.bias is trainable\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Print out the parameter settings to verify which are trainable or frozen\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"{name} is {'trainable' if param.requires_grad else 'frozen'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta.embeddings.word_embeddings.weight is frozen\n",
      "roberta.embeddings.position_embeddings.weight is frozen\n",
      "roberta.embeddings.token_type_embeddings.weight is frozen\n",
      "roberta.embeddings.LayerNorm.weight is frozen\n",
      "roberta.embeddings.LayerNorm.bias is frozen\n",
      "roberta.encoder.layer.0.attention.self.query.weight is frozen\n",
      "roberta.encoder.layer.0.attention.self.query.bias is frozen\n",
      "roberta.encoder.layer.0.attention.self.key.weight is frozen\n",
      "roberta.encoder.layer.0.attention.self.key.bias is frozen\n",
      "roberta.encoder.layer.0.attention.self.value.weight is frozen\n",
      "roberta.encoder.layer.0.attention.self.value.bias is frozen\n",
      "roberta.encoder.layer.0.attention.output.dense.weight is frozen\n",
      "roberta.encoder.layer.0.attention.output.dense.bias is frozen\n",
      "roberta.encoder.layer.0.attention.output.LayerNorm.weight is frozen\n",
      "roberta.encoder.layer.0.attention.output.LayerNorm.bias is frozen\n",
      "roberta.encoder.layer.0.intermediate.dense.weight is frozen\n",
      "roberta.encoder.layer.0.intermediate.dense.bias is frozen\n",
      "roberta.encoder.layer.0.output.dense.weight is frozen\n",
      "roberta.encoder.layer.0.output.dense.bias is frozen\n",
      "roberta.encoder.layer.0.output.LayerNorm.weight is frozen\n",
      "roberta.encoder.layer.0.output.LayerNorm.bias is frozen\n",
      "roberta.encoder.layer.1.attention.self.query.weight is frozen\n",
      "roberta.encoder.layer.1.attention.self.query.bias is frozen\n",
      "roberta.encoder.layer.1.attention.self.key.weight is frozen\n",
      "roberta.encoder.layer.1.attention.self.key.bias is frozen\n",
      "roberta.encoder.layer.1.attention.self.value.weight is frozen\n",
      "roberta.encoder.layer.1.attention.self.value.bias is frozen\n",
      "roberta.encoder.layer.1.attention.output.dense.weight is frozen\n",
      "roberta.encoder.layer.1.attention.output.dense.bias is frozen\n",
      "roberta.encoder.layer.1.attention.output.LayerNorm.weight is frozen\n",
      "roberta.encoder.layer.1.attention.output.LayerNorm.bias is frozen\n",
      "roberta.encoder.layer.1.intermediate.dense.weight is frozen\n",
      "roberta.encoder.layer.1.intermediate.dense.bias is frozen\n",
      "roberta.encoder.layer.1.output.dense.weight is frozen\n",
      "roberta.encoder.layer.1.output.dense.bias is frozen\n",
      "roberta.encoder.layer.1.output.LayerNorm.weight is frozen\n",
      "roberta.encoder.layer.1.output.LayerNorm.bias is frozen\n",
      "roberta.encoder.layer.2.attention.self.query.weight is frozen\n",
      "roberta.encoder.layer.2.attention.self.query.bias is frozen\n",
      "roberta.encoder.layer.2.attention.self.key.weight is frozen\n",
      "roberta.encoder.layer.2.attention.self.key.bias is frozen\n",
      "roberta.encoder.layer.2.attention.self.value.weight is frozen\n",
      "roberta.encoder.layer.2.attention.self.value.bias is frozen\n",
      "roberta.encoder.layer.2.attention.output.dense.weight is frozen\n",
      "roberta.encoder.layer.2.attention.output.dense.bias is frozen\n",
      "roberta.encoder.layer.2.attention.output.LayerNorm.weight is frozen\n",
      "roberta.encoder.layer.2.attention.output.LayerNorm.bias is frozen\n",
      "roberta.encoder.layer.2.intermediate.dense.weight is frozen\n",
      "roberta.encoder.layer.2.intermediate.dense.bias is frozen\n",
      "roberta.encoder.layer.2.output.dense.weight is frozen\n",
      "roberta.encoder.layer.2.output.dense.bias is frozen\n",
      "roberta.encoder.layer.2.output.LayerNorm.weight is frozen\n",
      "roberta.encoder.layer.2.output.LayerNorm.bias is frozen\n",
      "roberta.encoder.layer.3.attention.self.query.weight is frozen\n",
      "roberta.encoder.layer.3.attention.self.query.bias is frozen\n",
      "roberta.encoder.layer.3.attention.self.key.weight is frozen\n",
      "roberta.encoder.layer.3.attention.self.key.bias is frozen\n",
      "roberta.encoder.layer.3.attention.self.value.weight is frozen\n",
      "roberta.encoder.layer.3.attention.self.value.bias is frozen\n",
      "roberta.encoder.layer.3.attention.output.dense.weight is frozen\n",
      "roberta.encoder.layer.3.attention.output.dense.bias is frozen\n",
      "roberta.encoder.layer.3.attention.output.LayerNorm.weight is frozen\n",
      "roberta.encoder.layer.3.attention.output.LayerNorm.bias is frozen\n",
      "roberta.encoder.layer.3.intermediate.dense.weight is frozen\n",
      "roberta.encoder.layer.3.intermediate.dense.bias is frozen\n",
      "roberta.encoder.layer.3.output.dense.weight is frozen\n",
      "roberta.encoder.layer.3.output.dense.bias is frozen\n",
      "roberta.encoder.layer.3.output.LayerNorm.weight is frozen\n",
      "roberta.encoder.layer.3.output.LayerNorm.bias is frozen\n",
      "roberta.encoder.layer.4.attention.self.query.weight is frozen\n",
      "roberta.encoder.layer.4.attention.self.query.bias is frozen\n",
      "roberta.encoder.layer.4.attention.self.key.weight is frozen\n",
      "roberta.encoder.layer.4.attention.self.key.bias is frozen\n",
      "roberta.encoder.layer.4.attention.self.value.weight is frozen\n",
      "roberta.encoder.layer.4.attention.self.value.bias is frozen\n",
      "roberta.encoder.layer.4.attention.output.dense.weight is frozen\n",
      "roberta.encoder.layer.4.attention.output.dense.bias is frozen\n",
      "roberta.encoder.layer.4.attention.output.LayerNorm.weight is frozen\n",
      "roberta.encoder.layer.4.attention.output.LayerNorm.bias is frozen\n",
      "roberta.encoder.layer.4.intermediate.dense.weight is frozen\n",
      "roberta.encoder.layer.4.intermediate.dense.bias is frozen\n",
      "roberta.encoder.layer.4.output.dense.weight is frozen\n",
      "roberta.encoder.layer.4.output.dense.bias is frozen\n",
      "roberta.encoder.layer.4.output.LayerNorm.weight is frozen\n",
      "roberta.encoder.layer.4.output.LayerNorm.bias is frozen\n",
      "roberta.encoder.layer.5.attention.self.query.weight is frozen\n",
      "roberta.encoder.layer.5.attention.self.query.bias is frozen\n",
      "roberta.encoder.layer.5.attention.self.key.weight is frozen\n",
      "roberta.encoder.layer.5.attention.self.key.bias is frozen\n",
      "roberta.encoder.layer.5.attention.self.value.weight is frozen\n",
      "roberta.encoder.layer.5.attention.self.value.bias is frozen\n",
      "roberta.encoder.layer.5.attention.output.dense.weight is frozen\n",
      "roberta.encoder.layer.5.attention.output.dense.bias is frozen\n",
      "roberta.encoder.layer.5.attention.output.LayerNorm.weight is frozen\n",
      "roberta.encoder.layer.5.attention.output.LayerNorm.bias is frozen\n",
      "roberta.encoder.layer.5.intermediate.dense.weight is frozen\n",
      "roberta.encoder.layer.5.intermediate.dense.bias is frozen\n",
      "roberta.encoder.layer.5.output.dense.weight is frozen\n",
      "roberta.encoder.layer.5.output.dense.bias is frozen\n",
      "roberta.encoder.layer.5.output.LayerNorm.weight is frozen\n",
      "roberta.encoder.layer.5.output.LayerNorm.bias is frozen\n",
      "roberta.encoder.layer.6.attention.self.query.weight is frozen\n",
      "roberta.encoder.layer.6.attention.self.query.bias is frozen\n",
      "roberta.encoder.layer.6.attention.self.key.weight is frozen\n",
      "roberta.encoder.layer.6.attention.self.key.bias is frozen\n",
      "roberta.encoder.layer.6.attention.self.value.weight is frozen\n",
      "roberta.encoder.layer.6.attention.self.value.bias is frozen\n",
      "roberta.encoder.layer.6.attention.output.dense.weight is frozen\n",
      "roberta.encoder.layer.6.attention.output.dense.bias is frozen\n",
      "roberta.encoder.layer.6.attention.output.LayerNorm.weight is frozen\n",
      "roberta.encoder.layer.6.attention.output.LayerNorm.bias is frozen\n",
      "roberta.encoder.layer.6.intermediate.dense.weight is frozen\n",
      "roberta.encoder.layer.6.intermediate.dense.bias is frozen\n",
      "roberta.encoder.layer.6.output.dense.weight is frozen\n",
      "roberta.encoder.layer.6.output.dense.bias is frozen\n",
      "roberta.encoder.layer.6.output.LayerNorm.weight is frozen\n",
      "roberta.encoder.layer.6.output.LayerNorm.bias is frozen\n",
      "roberta.encoder.layer.7.attention.self.query.weight is frozen\n",
      "roberta.encoder.layer.7.attention.self.query.bias is frozen\n",
      "roberta.encoder.layer.7.attention.self.key.weight is frozen\n",
      "roberta.encoder.layer.7.attention.self.key.bias is frozen\n",
      "roberta.encoder.layer.7.attention.self.value.weight is frozen\n",
      "roberta.encoder.layer.7.attention.self.value.bias is frozen\n",
      "roberta.encoder.layer.7.attention.output.dense.weight is frozen\n",
      "roberta.encoder.layer.7.attention.output.dense.bias is frozen\n",
      "roberta.encoder.layer.7.attention.output.LayerNorm.weight is frozen\n",
      "roberta.encoder.layer.7.attention.output.LayerNorm.bias is frozen\n",
      "roberta.encoder.layer.7.intermediate.dense.weight is frozen\n",
      "roberta.encoder.layer.7.intermediate.dense.bias is frozen\n",
      "roberta.encoder.layer.7.output.dense.weight is frozen\n",
      "roberta.encoder.layer.7.output.dense.bias is frozen\n",
      "roberta.encoder.layer.7.output.LayerNorm.weight is frozen\n",
      "roberta.encoder.layer.7.output.LayerNorm.bias is frozen\n",
      "roberta.encoder.layer.8.attention.self.query.weight is frozen\n",
      "roberta.encoder.layer.8.attention.self.query.bias is frozen\n",
      "roberta.encoder.layer.8.attention.self.key.weight is frozen\n",
      "roberta.encoder.layer.8.attention.self.key.bias is frozen\n",
      "roberta.encoder.layer.8.attention.self.value.weight is frozen\n",
      "roberta.encoder.layer.8.attention.self.value.bias is frozen\n",
      "roberta.encoder.layer.8.attention.output.dense.weight is frozen\n",
      "roberta.encoder.layer.8.attention.output.dense.bias is frozen\n",
      "roberta.encoder.layer.8.attention.output.LayerNorm.weight is frozen\n",
      "roberta.encoder.layer.8.attention.output.LayerNorm.bias is frozen\n",
      "roberta.encoder.layer.8.intermediate.dense.weight is frozen\n",
      "roberta.encoder.layer.8.intermediate.dense.bias is frozen\n",
      "roberta.encoder.layer.8.output.dense.weight is frozen\n",
      "roberta.encoder.layer.8.output.dense.bias is frozen\n",
      "roberta.encoder.layer.8.output.LayerNorm.weight is frozen\n",
      "roberta.encoder.layer.8.output.LayerNorm.bias is frozen\n",
      "roberta.encoder.layer.9.attention.self.query.weight is frozen\n",
      "roberta.encoder.layer.9.attention.self.query.bias is frozen\n",
      "roberta.encoder.layer.9.attention.self.key.weight is frozen\n",
      "roberta.encoder.layer.9.attention.self.key.bias is frozen\n",
      "roberta.encoder.layer.9.attention.self.value.weight is frozen\n",
      "roberta.encoder.layer.9.attention.self.value.bias is frozen\n",
      "roberta.encoder.layer.9.attention.output.dense.weight is frozen\n",
      "roberta.encoder.layer.9.attention.output.dense.bias is frozen\n",
      "roberta.encoder.layer.9.attention.output.LayerNorm.weight is frozen\n",
      "roberta.encoder.layer.9.attention.output.LayerNorm.bias is frozen\n",
      "roberta.encoder.layer.9.intermediate.dense.weight is frozen\n",
      "roberta.encoder.layer.9.intermediate.dense.bias is frozen\n",
      "roberta.encoder.layer.9.output.dense.weight is frozen\n",
      "roberta.encoder.layer.9.output.dense.bias is frozen\n",
      "roberta.encoder.layer.9.output.LayerNorm.weight is frozen\n",
      "roberta.encoder.layer.9.output.LayerNorm.bias is frozen\n",
      "roberta.encoder.layer.10.attention.self.query.weight is trainable\n",
      "roberta.encoder.layer.10.attention.self.query.bias is trainable\n",
      "roberta.encoder.layer.10.attention.self.key.weight is trainable\n",
      "roberta.encoder.layer.10.attention.self.key.bias is trainable\n",
      "roberta.encoder.layer.10.attention.self.value.weight is trainable\n",
      "roberta.encoder.layer.10.attention.self.value.bias is trainable\n",
      "roberta.encoder.layer.10.attention.output.dense.weight is trainable\n",
      "roberta.encoder.layer.10.attention.output.dense.bias is trainable\n",
      "roberta.encoder.layer.10.attention.output.LayerNorm.weight is trainable\n",
      "roberta.encoder.layer.10.attention.output.LayerNorm.bias is trainable\n",
      "roberta.encoder.layer.10.intermediate.dense.weight is trainable\n",
      "roberta.encoder.layer.10.intermediate.dense.bias is trainable\n",
      "roberta.encoder.layer.10.output.dense.weight is trainable\n",
      "roberta.encoder.layer.10.output.dense.bias is trainable\n",
      "roberta.encoder.layer.10.output.LayerNorm.weight is trainable\n",
      "roberta.encoder.layer.10.output.LayerNorm.bias is trainable\n",
      "roberta.encoder.layer.11.attention.self.query.weight is trainable\n",
      "roberta.encoder.layer.11.attention.self.query.bias is trainable\n",
      "roberta.encoder.layer.11.attention.self.key.weight is trainable\n",
      "roberta.encoder.layer.11.attention.self.key.bias is trainable\n",
      "roberta.encoder.layer.11.attention.self.value.weight is trainable\n",
      "roberta.encoder.layer.11.attention.self.value.bias is trainable\n",
      "roberta.encoder.layer.11.attention.output.dense.weight is trainable\n",
      "roberta.encoder.layer.11.attention.output.dense.bias is trainable\n",
      "roberta.encoder.layer.11.attention.output.LayerNorm.weight is trainable\n",
      "roberta.encoder.layer.11.attention.output.LayerNorm.bias is trainable\n",
      "roberta.encoder.layer.11.intermediate.dense.weight is trainable\n",
      "roberta.encoder.layer.11.intermediate.dense.bias is trainable\n",
      "roberta.encoder.layer.11.output.dense.weight is trainable\n",
      "roberta.encoder.layer.11.output.dense.bias is trainable\n",
      "roberta.encoder.layer.11.output.LayerNorm.weight is trainable\n",
      "roberta.encoder.layer.11.output.LayerNorm.bias is trainable\n",
      "classifier.dense.weight is trainable\n",
      "classifier.dense.bias is trainable\n",
      "classifier.out_proj.weight is trainable\n",
      "classifier.out_proj.bias is trainable\n"
     ]
    }
   ],
   "source": [
    "# # Freeze all parameters first\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# # Set the last two layers of the encoder and the classifier to be trainable\n",
    "# layer_indices = [10, 11]  # The last two layers\n",
    "\n",
    "# for i, layer in enumerate(model.roberta.encoder.layer):\n",
    "#     if i in layer_indices:\n",
    "#         for param in layer.parameters():\n",
    "#             param.requires_grad = True\n",
    "\n",
    "# # Make classifier layer trainable\n",
    "# for param in model.classifier.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "# # Verify which parameters are trainable\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"{name} is {'trainable' if param.requires_grad else 'frozen'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Tokenize the test dataset\n",
    "# def prepare_data(texts, tokenizer, max_length=512):\n",
    "#     encoding = tokenizer(texts, truncation=True, padding=\"max_length\", max_length=max_length, return_tensors=\"pt\")\n",
    "#     return encoding\n",
    "\n",
    "# predictions = []\n",
    "# probabilities = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8900\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# # Iterate over sampled data to predict and collect probabilities\n",
    "# for index, row in sampled_df.iterrows():\n",
    "#     encoded_input = prepare_data(row['sentences'], tokenizer)\n",
    "#     encoded_input = {key: value.to(model.device) for key, value in encoded_input.items()}\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**encoded_input)\n",
    "#         probs = torch.nn.functional.softmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "#         predictions.append(probs.argmax(axis=-1)[0])\n",
    "#         probabilities.append(probs[0, 1])\n",
    "\n",
    "# # Store predictions and probabilities in the DataFrame\n",
    "# sampled_df['predictions'] = predictions\n",
    "# sampled_df['probabilities'] = probabilities\n",
    "\n",
    "# # Calculate accuracy of the predictions\n",
    "# actual_labels = sampled_df['label'].values\n",
    "# accuracy = accuracy_score(actual_labels, predictions)\n",
    "# print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
