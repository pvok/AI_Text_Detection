{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from numpy import array\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('LLM_vs_human_train_50k.csv')\n",
    "val_df = pd.read_csv('LLM_vs_human_val_1k.csv')\n",
    "# test_df = pd.read_csv('LLM_vs_human_test_1k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop('Unnamed: 0',axis = 1, inplace = True)\n",
    "train_df.reset_index(inplace = True)\n",
    "train_df.drop('index',axis = 1, inplace = True)\n",
    "val_df.drop('Unnamed: 0',axis = 1, inplace = True)\n",
    "val_df.reset_index(inplace = True)\n",
    "val_df.drop('index',axis = 1, inplace = True)\n",
    "# test_df.drop('Unnamed: 0',axis = 1, inplace = True)\n",
    "# test_df.reset_index(inplace = True)\n",
    "# test_df.drop('index',axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm not happy with what I've wrote to be hones...</td>\n",
       "      <td>Human</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Postmodernist Anthropology and its Impact on T...</td>\n",
       "      <td>Human</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Firstly, is it okay to write an essay or does ...</td>\n",
       "      <td>Human</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nissan Company’s Operational Changes and Manag...</td>\n",
       "      <td>Human</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I think some people might find visiting a nati...</td>\n",
       "      <td>Human</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>The exploration of space has always captivated...</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Famous people, whether they are actors, athlet...</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>The future of 3D printing and its applications...</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>The world is currently facing a critical issue...</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>Native American medicine bags hold a significa...</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text   source  label\n",
       "0      I'm not happy with what I've wrote to be hones...    Human      0\n",
       "1      Postmodernist Anthropology and its Impact on T...    Human      0\n",
       "2      Firstly, is it okay to write an essay or does ...    Human      0\n",
       "3      Nissan Company’s Operational Changes and Manag...    Human      0\n",
       "4      I think some people might find visiting a nati...    Human      0\n",
       "...                                                  ...      ...    ...\n",
       "49995  The exploration of space has always captivated...  GPT-3.5      1\n",
       "49996  Famous people, whether they are actors, athlet...  GPT-3.5      1\n",
       "49997  The future of 3D printing and its applications...  GPT-3.5      1\n",
       "49998  The world is currently facing a critical issue...  GPT-3.5      1\n",
       "49999  Native American medicine bags hold a significa...  GPT-3.5      1\n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human : 0, LLM : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_train = train_df['text'].astype(str).values\n",
    "lbl_train = train_df['label'].values\n",
    "txt_val = val_df['text'].astype(str).values\n",
    "lbl_val = val_df['label'].values\n",
    "# txt_test = test_df['text'].astype(str).values\n",
    "# lbl_test = test_df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['text'].str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postmodernist Anthropology and its Impact on Translation Practice Research Paper\n",
      "\n",
      "It would be fair enough to state that translation in its practical use appeared together with the appearance of the mankind. Not only finding the lexical equivalents, but also interpreting one’s thoughts and ideas, and conveying the meaning of different signs were the tasks of translation at that time. Nowadays the process of translation is even more complex, and simply knowing two languages does not make one a translator.\n",
      "\n",
      "What is more, with the development of the humanity, more and more translation problems occur, and the number of skills needed to translate is increasing constantly. As it can be seen, translation is realized by humans and for humans, which means that these two notions are inseparable. For this reason, the interdependence between the translation and anthropology, the study of humans, is hard to overestimate.\n",
      "\n",
      "Indeed, one of the fundamental tasks of anthropology is understanding different cultures, which “inevitably involves either the translation of words, ideas, and meanings from one culture to another, or the translation to a set of analytical concepts” (Rubel, 1).\n",
      "\n",
      "This means that translation in all its forms is crucial for anthropology. On the other hand, translation cannot exist separately from anthropology; knowledge of the cultural background is as important as knowledge of language grammar for a good translation. That is why, the translator’s practice is always connected to the anthropological studies.\n",
      "\n",
      "However, despite the interdependence of the two disciplines, there was a period in history, when anthropological ideas and translator’s principles encountered. Specifically, the post-modern anthropology denied the possibility of effective learning about other cultures.\n",
      "\n",
      "For instance, the post-modernist ideas in the field of anthropology were based on the opinion that “anthropology could recognize, respect, and celebrate differences between cultures, only, it appears, by effacing differences within cultures” (Coombe, 191).\n",
      "\n",
      "In other words, postmodernist anthropologists defended the point of view that any attempt to learn and understand other culture is destined to fail, as far as there is no way of comprehending the other culture other than being a part of it.\n",
      "\n",
      "This excluded the traditional need for translation, in which the attempts to understand cultures were crucial. Thus, such tendencies in the anthropological theory had a great impact on the development of practical translation patterns.\n",
      "\n",
      "It may seem that the occurrence of the mentioned ideas in anthropology decreased the importance of translation. Indeed, if the scientists focused on studying a local culture, there was no more need to translate from and to other languages.\n",
      "\n",
      "In addition, the cross-cultural and comparative studies became less spread, leading to a lower level of cultural exchange. However, in reality these changes did not reject the translation, but changed it considerably.\n",
      "\n",
      "First of all, while describing the influence of the postmodernist anthropology on translator’s practice, it is worth mentioning that the deeper understanding of the native language was developed.\n",
      "\n",
      "Studying the local culture allowed the anthropologists collect much information about the language history, its development, differences in use in various regions, etc.\n",
      "\n",
      "As a result, the ethnographical background of the language was investigated, including the etymology and origin of the words. This suggests that the translators were first of all linguists, who had a sense of their own language. This quality is crucial for translation into the translator’s native language.\n",
      "\n",
      "What is more, due to the decrease in the cross-cultural exchange, all the languages became “purer”. This means that the languages were isolated from the borrowings, internationalisms, and barbarisms, which allowed preserving the ethnic flavor and original sounding of the language.\n",
      "\n",
      "In contrast, nowadays the process of globalization suggests that every language is overfilled with the words, which have the same meaning in every part of the world. From this point of view, it can be said that the translation according to the principles of the postmodern anthropology became rich in relation to national coloring.\n",
      "\n",
      "As far as the postmodern anthropology was practiced all around the world, this process has “purified” all the languages. This created a firm foundation for the further cultural exchange, which was on its peak a bit later. One more peculiarity of the translator’s practice was that the translations had a more local orientation.\n",
      "\n",
      "While earlier the translations seek to “address different audiences and meet different expectations” (Hansen, 34), now they oriented their works at a certain type of audience. In other words, with the narrowing down of the culture studies, the translation efficiency has increased.\n",
      "\n",
      "The translators therefore did not address their works to the audience that was aware of the cultural differences between various communities anymore; they knew that the members of the audience were rather bounded with the traditional models of world perception, determined by their own culture.\n",
      "\n",
      "Based on the evidence given below, it may seem logical that the task of the translator is to render the meaning of the source language message into the target language; however, the cultures of the two nationalities should not be mixed.\n",
      "\n",
      "As some anthropologists noted, from the point of view of cultures, the translators should preserve “the idiosyncrasies of both the domestic and foreign cultures in their common ground, i.e. in pure language” (Muller, 74). However, this concept differs from what we call a translation nowadays.\n",
      "\n",
      "Indeed, today the translator’s practice demands making a research about the traditions and history of the other nation; moreover, descriptive translation, where the cultural differences are being decoded, is often preferred to the word for word or faithful translation. This can be explained by the fact that the fullest translation is the one that renders the original meaning rather than simply gives a corresponding vocabulary variant.\n",
      "\n",
      "In order to prove what had been previously said, several examples can be given. The expression “Uncle Sam” is well-known to all the Americans; however, how should it be translated to an audience in an Uzbek village? Another case is the Russian name Vanka, which is often used to address an infantile and unserious man.\n",
      "\n",
      "In other languages there is no such equivalent, so for example to English this word would be translated simply as “clown.” Obviously, not taking into consideration the national peculiarities and ethnographical differences puts the translation at risk of being irrelevant and misinterpreting.\n",
      "\n",
      "All in all, it should be said that the translation as a practical application of language and anthropology as a study of civilization are mutually dependent. The postmodernist anthropological ideas influenced the translation practice in a way that involved separating cultures one from another rather than integrating them into one.\n",
      "\n",
      "On one hand, this tendency was rather positive in terms of national coloring preservation and vocabulary organization. On the other hand, it was rather limiting because of its rejection of multi-cultural exchange. Thus, this approach, as any other approach in science, cannot be considered as neither ultimately misleading or totally sufficient.\n",
      "\n",
      "Works Cited\n",
      "\n",
      "Coombe, Rosemary 1991, “Encountering the postmodern: new directions in cultural anthropology”. Canadian Association of Sociology and Anthropology , vol. 28(2).\n",
      "\n",
      "Hansen, Gyde, Malmkaer, Kirsten, Gile, Daniel 2003. Claims, changes, and challenges in translation studies . EST Congress, Copenhagen.\n",
      "\n",
      "Muller, Klaus 1995, “Transferring culture in translation – modern and postmodern options”. Traduction, Terminologie, Redaction , vol.8 (1), p.65-83.\n",
      "\n",
      "Rubel, Paula, Rosman, Abraham 2003. Translating cultures: perspectives on translation and anthropology . Berg, Oxford.\n",
      "\n",
      "[3, 32, 91, 12, 3680, 486, 110, 375, 11, 59, 16, 1434, 685, 4, 234, 8, 3680, 5, 32, 1251, 64, 3440, 435, 13, 1, 2537, 2, 1, 26, 81, 1472, 1, 38, 29, 2323, 1249, 3, 441, 3, 1, 888, 2, 93, 2866, 54, 1, 1055, 2, 3680, 35, 8, 40, 3534, 1, 126, 2, 3680, 7, 116, 31, 263, 3, 1155, 2263, 144, 1395, 288, 26, 94, 34, 6, 82, 7, 31, 13, 1, 87, 2, 1, 1338, 31, 3, 31, 3680, 357, 1727, 3, 1, 242, 2, 246, 745, 4, 7, 723, 1268, 10, 11, 18, 16, 466, 3680, 7, 1192, 19, 847, 3, 9, 847, 30, 262, 8, 36, 144, 3119, 15, 9, 14, 543, 1, 89, 1, 3680, 3, 1, 184, 2, 847, 7, 627, 4, 1823, 34, 2, 1, 822, 1055, 2, 7, 136, 93, 613, 30, 841, 995, 1, 3680, 2, 661, 441, 3, 4776, 24, 34, 199, 4, 154, 27, 1, 3680, 4, 6, 364, 2, 4313, 111, 14, 262, 8, 3680, 5, 48, 32, 564, 7, 220, 9, 12, 1, 42, 292, 3680, 406, 1392, 24, 171, 2, 1, 114, 1400, 7, 10, 99, 10, 171, 2, 319, 4738, 9, 6, 172, 3680, 8, 7, 305, 1, 486, 7, 248, 1564, 4, 1, 547, 75, 409, 1, 2, 1, 144, 4411, 44, 23, 6, 571, 5, 235, 58, 441, 3, 561, 3652, 2033, 1, 1222, 275, 4613, 1, 1484, 2, 313, 166, 46, 42, 613, 9, 421, 1, 1222, 441, 5, 1, 429, 2, 54, 148, 12, 1, 818, 8, 83, 1073, 853, 3, 3356, 963, 89, 613, 81, 11, 2597, 19, 963, 151, 5, 42, 661, 1, 440, 2, 605, 8, 123, 1857, 4, 444, 3, 316, 42, 199, 7, 4, 2234, 10, 458, 10, 44, 7, 106, 76, 2, 1, 42, 199, 42, 105, 84, 6, 240, 2, 11, 14, 1, 192, 120, 9, 3680, 5, 30, 1, 2572, 4, 316, 613, 54, 220, 277, 39, 5, 1, 341, 55, 6, 265, 91, 12, 1, 87, 2, 1251, 3680, 1010, 11, 63, 1292, 8, 1, 3639, 2, 1, 1359, 441, 5, 2905, 1, 371, 2, 3680, 1823, 70, 1, 830, 1304, 12, 1711, 6, 346, 199, 44, 23, 106, 31, 120, 4, 24, 3, 4, 42, 1395, 5, 174, 1, 1741, 114, 3, 4378, 547, 548, 451, 987, 266, 4, 6, 916, 271, 2, 114, 1070, 75, 5, 425, 36, 338, 334, 26, 1, 3680, 38, 1229, 11, 4877, 125, 2, 48, 78, 1, 214, 2, 1, 12, 486, 11, 7, 1330, 8, 1, 1130, 136, 2, 1, 1597, 319, 23, 531, 1711, 1, 346, 199, 809, 1, 3200, 236, 96, 46, 1, 319, 235, 32, 87, 963, 5, 64, 5, 141, 1118, 1756, 10, 6, 237, 1, 1400, 2, 1, 319, 23, 311, 1, 3, 2652, 2, 1, 661, 14, 1872, 8, 1, 54, 125, 2, 48, 56, 55, 6, 186, 2, 17, 158, 319, 14, 203, 7, 220, 9, 3680, 62, 1, 1597, 319, 82, 7, 31, 228, 4, 1, 1739, 5, 1, 1741, 114, 1070, 48, 1, 1395, 548, 14, 262, 8, 1, 1395, 54, 4038, 24, 1, 3, 30, 809, 1605, 1, 2463, 3, 1803, 2, 1, 319, 5, 1799, 3534, 1, 126, 2, 1500, 1872, 8, 250, 319, 7, 13, 1, 661, 30, 20, 1, 195, 888, 5, 250, 240, 2, 1, 52, 24, 14, 440, 2, 605, 11, 18, 16, 330, 8, 1, 3680, 282, 4, 1, 561, 2, 1, 548, 911, 5, 2064, 4, 493, 10, 458, 10, 1, 23, 4660, 48, 178, 1, 52, 14, 126, 21, 48, 1, 1395, 14, 758, 6, 769, 1492, 9, 1, 312, 114, 1070, 30, 23, 12, 32, 4634, 6, 2180, 887, 34, 31, 2, 1, 486, 23, 8, 1, 55, 6, 31, 346, 3243, 78, 1826, 1, 920, 4, 93, 1559, 3, 872, 93, 2969, 300, 25, 2888, 17, 352, 35, 6, 323, 838, 2, 812, 5, 42, 661, 13, 1, 321, 2, 1, 199, 547, 1, 3680, 868, 21, 376, 1, 176, 334, 26, 397, 17, 352, 4, 1, 812, 8, 23, 1485, 2, 1, 114, 963, 89, 141, 219, 4354, 25, 989, 8, 1, 443, 2, 1, 812, 54, 407, 13, 1, 192, 1075, 2, 52, 1054, 1645, 19, 17, 158, 199, 148, 12, 1, 659, 358, 1615, 11, 63, 1292, 3762, 8, 1, 1140, 2, 1, 7, 4, 1, 888, 2, 1, 456, 319, 1482, 62, 1, 1090, 319, 75, 1, 613, 2, 1, 144, 65, 26, 16, 2955, 10, 67, 1765, 24, 1, 440, 2, 605, 2, 613, 1, 65, 2154, 1108, 2, 132, 1, 1689, 3, 857, 613, 5, 17, 498, 1542, 22, 452, 5, 4228, 75, 14, 296, 24, 82, 41, 1277, 6, 3680, 3534, 1823, 608, 1, 486, 1751, 150, 6, 110, 46, 1, 854, 3, 235, 2, 1, 42, 1239, 247, 3680, 109, 1, 114, 963, 15, 84, 7, 133, 3425, 4, 1, 1365, 9, 1365, 27, 3680, 14, 18, 16, 2037, 19, 1, 294, 8, 1, 3680, 7, 1, 34, 8, 1, 1803, 888, 407, 105, 1155, 1256, 6, 4773, 5, 209, 4, 2210, 82, 55, 51, 1946, 330, 356, 1367, 18, 16, 358, 1, 907, 7, 72, 398, 4, 48, 1, 1112, 75, 92, 65, 11, 16, 4, 28, 812, 5, 28, 2997, 154, 222, 7, 1, 3728, 759, 30, 7, 133, 101, 4, 397, 28, 3, 563, 5, 42, 1395, 44, 7, 106, 39, 85, 9, 145, 4, 1015, 14, 1365, 59, 16, 1155, 10, 343, 4578, 26, 562, 62, 861, 1, 493, 3, 963, 4173, 1, 3680, 35, 339, 2, 84, 3, 48, 5, 48, 11, 65, 16, 330, 8, 1, 3680, 10, 6, 1251, 1197, 2, 319, 3, 10, 6, 184, 2, 2554, 15, 2423, 1, 441, 940, 1, 3680, 486, 5, 6, 76, 8, 556, 613, 34, 24, 154, 407, 105, 2683, 60, 62, 34, 12, 34, 292, 14, 3421, 23, 407, 320, 5, 573, 2, 493, 1327, 3, 4773, 283, 12, 1, 42, 292, 11, 23, 407, 1866, 77, 2, 32, 4434, 2, 2351, 114, 1070, 277, 14, 218, 10, 123, 42, 218, 5, 402, 406, 16, 454, 10, 4180, 691, 27, 4401, 2389, 352, 927, 3656, 1, 53, 4587, 5, 114, 3005, 1800, 2, 3, 1001, 2790, 135, 879, 2248, 338, 3, 137, 5, 3680, 547, 3175, 2638, 199, 5, 3680, 503, 275, 3, 1001, 739, 111, 161, 3725, 879, 613, 766, 12, 3680, 3, 2335]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(txt_train)\n",
    "token_train = tokenizer.texts_to_sequences(txt_train)\n",
    "token_val = tokenizer.texts_to_sequences(txt_val)\n",
    "# token_test = tokenizer.texts_to_sequences(txt_test)\n",
    "vocab_size = len(tokenizer.word_index) + 1  \n",
    "print(txt_train[1])\n",
    "print(token_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 669   26 1474   13   82 1644 3744    4   16 4269   22  475  302   32\n",
      "  162 2036   38 2755  722    2 3176   35   47  826    5    6 1457 1096\n",
      "   47  930    1   81    1 1096   23 1628   13    6    2   10   45    5\n",
      "   31 1845    2 1326   62    1  826  154   45  545   47 1149    4  178\n",
      "   47  912 1447   25  364  614    6  424  874    1  722    2 2688   30\n",
      "  111    6   63   26    6   68   84   27   61  814    6   68   84    4\n",
      "  274    4 1366  135    6  226    1 3791  358    4   11   19   68 1437\n",
      " 3942  109   39 3791   59  699   13    1  125  367  170    6  226  760\n",
      "   32  158  641   10  179   10   39  974  288   26  699   13    1  125\n",
      "   27  510  367   45    6  657   63   20   51    6 2835   38   47  722\n",
      "   12  919  560 2251 1789 2755    1  222   47  416   12    1  826 2484\n",
      "    3  779    4  838  851 1600 2268    3  649  726   45 3864   47 1375\n",
      "  622   24    1  826 2484  267    1 1139   30 2505    5    1 2966    2\n",
      "    1 1096 2201  121  250 3852    4    1 1518   85  236   80   23   26\n",
      "   46    4   16   19    6  890 3733   45 3193    4   47  826    3 4596\n",
      "    6 3314    1 2587 1726  635    1  644  655   67 3893 1789   67   35\n",
      " 1351   26  562  228  281    5  345    4   16  801  183 3951   87   55\n",
      "  159   61  197  983    2   48 1060   55    4   16  138   30  138   11\n",
      " 1137  627    4  177    6  203 3326 2755    1  222   11   23   26 1330\n",
      "    3 3623  123 1205    1   33 1789  274    4    3   45   23  128   84\n",
      " 1714    1 3314   45    4    1 3314    1  326 1326    1  634   84    4\n",
      " 1326    5 2300   13    1  326  131    3  208 2711    4   93  501  271\n",
      " 1591 1478    6   12   47    4    1 1139    3  208 4304   47  121    1\n",
      " 2808   13    6  829 3805   45    1  208 3864  178    4  325   47   53\n",
      "  793   30  288 1185    6    2 3280 3864    4   47  826  851    3    1\n",
      " 3314    1  143 2089   82   45  801    1  919    5    1 2966    2    1\n",
      " 1096   23  300 1640   13   32  224 1994   35  833 1156  484  304    4\n",
      "    1 1326 3314  154 1326   62    1  919   14   40   34    4   32   69\n",
      " 1206 1266    1 3314 2798   14 2499    4   29   16  733    1 1086  130\n",
      " 1994    4   47  793   11   65  300   16  182    4  157  281    2    8\n",
      "  892  726   45  545   47 1149    4  121    4    8  195 1892  851 2416\n",
      "   47 1149   12    1  424  759   35    1 3532  301 3283   92 1193   43\n",
      "   54   45    4 1450   11    7   26  685    9    6 1518    4   16   11\n",
      "  642  765   10   72   12   32  158    7   26  685    8 1518    8 1954\n",
      "  121   44    7   38   11   21  106  765    9   82  543   59   11  620\n",
      "   32 1149    9   82  543   59   11  778   32 1375   27  905   32   44\n",
      "    7 3887   11   23  758  198  900    3  176   21  106    4  100  965\n",
      "   45 1047    6  829 3805  239 4524   47    6   68   84    9  145    7\n",
      " 1890   13    6  765    4  444  594    3  903    5   32   73   33   16\n",
      "   19   36  432  572   16   11  305   11 1487    4  165   27  305   11\n",
      " 2153    6  426   27  305   11   63  525   11    7   81    4  624   36\n",
      "  432  627  572 2894  304    4   47  826 2484   45  144   31 1326    1\n",
      "  125   34   84    6  424  124 3299    1 1207    4  444    1  510    6\n",
      "  833  761    5  271 1015    5    6 4108    1  919  846   59  316   59\n",
      "   20    4 2689    1  919   96   45 1124   11    4   11   23   28 1258\n",
      "  924    6  826    8   18  444   85   11   23   26  278    4 1293  965\n",
      "   38 1591 1478   45 3802    1 3314   10    1  846    1  319  761   11\n",
      "   59  157   81    6  523 1600  228    4    1    2   32  846  914    4\n",
      "    6  847   38   11   59  252  157   40    5    1 2331  809   47 1149\n",
      "    4 1383   12    1  874  851   14   40   47 1149 1304   12    1 1153\n",
      "    1  326  404  175 1504    7   45   36   15  722    9  847   26   28\n",
      "  919   59  387 3695 3738  104 3738 3738  760   32  158   73   11   23\n",
      "    4  100   85  847   15    1   81  543   59  630 1269   27 1270   36\n",
      "  722  198    6    4  765   25   33  100 1185   38 1392    1  913 2919\n",
      "   12   47 2314  655    8    1  919   21 3290   32  166    2 1015   47\n",
      " 1149  622   24    1  874    3 3733   13    1 3147    6 1491    2 1326\n",
      "  175 2321   13  141 1478   39   10    1  136    2 1149    3 3719 3286\n",
      "    3  658    3 1417   10   72   10    6 2427    2  194   36 1949    3\n",
      "    1  404   24   32    9   11    4 2252  731    3  658   12   32 3286\n",
      "   45 2153   86    3 3864    4  325    1 2966    2    1 1096  267    1\n",
      " 1139  300  208  239   22   43    4    1  731    2    1  467   22  226\n",
      "  100   34 1491  945    1  919 4596   32 1149    3 2354    1  100   43\n",
      "  983  716    1  919    9    6 1037  546 1634    5  540  106  208   43\n",
      "   20   51    6  355   48   49 1300   54 2251   45   47 1430    5    4\n",
      "    1  731    2    1  467   45 1402    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "pad_token_train = pad_sequences(token_train, padding='post', maxlen=max_len)\n",
    "pad_token_val = pad_sequences(token_val, padding='post', maxlen=max_len)\n",
    "# pad_token_test = pad_sequences(token_test, padding='post', maxlen=max_len)\n",
    "print(pad_token_train[0, :]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pad_token_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202332"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(length, vocab_size):\n",
    " \n",
    " inputs = Input(shape=(length,))\n",
    " embedding1 = Embedding(vocab_size, 1024)(inputs)\n",
    " conv1 = Conv1D(filters=2048, kernel_size=4, activation='relu')(embedding1)\n",
    " conv2 = Conv1D(filters=1024, kernel_size=4, activation='relu')(conv1)\n",
    " conv3 = Conv1D(filters=512, kernel_size=4, activation='relu')(conv2)\n",
    " pool1 = MaxPooling1D(pool_size=2)(conv3)\n",
    " conv4 = Conv1D(filters=128, kernel_size=4, activation='relu')(pool1)\n",
    " conv5 = Conv1D(filters=64, kernel_size=4, activation='relu')(conv4)\n",
    " drop1 = Dropout(0.3)(conv5)\n",
    " pool2 = MaxPooling1D(pool_size=2)(drop1)\n",
    " flat1 = Flatten()(pool2)\n",
    " dense1 = Dense(100, activation='relu')(flat1)\n",
    " outputs = Dense(1, activation='sigmoid')(dense1)\n",
    " model = Model(inputs= inputs, outputs=outputs)\n",
    " # compile\n",
    " model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    " return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = define_model(max_len, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │   <span style=\"color: #00af00; text-decoration-color: #00af00\">207,187,968</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">997</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,390,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">994</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,389,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">991</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">495</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">492</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">489</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">489</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15616</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,561,700</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │   \u001b[38;5;34m207,187,968\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m997\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │     \u001b[38;5;34m8,390,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m994\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │     \u001b[38;5;34m8,389,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m991\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │     \u001b[38;5;34m2,097,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m495\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m492\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m262,272\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m489\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m32,832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m489\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15616\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │     \u001b[38;5;34m1,561,700\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m101\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">227,922,825</span> (869.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m227,922,825\u001b[0m (869.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">227,922,825</span> (869.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m227,922,825\u001b[0m (869.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gehna\\Documents\\MSCS\\Sem2\\Deep_Learning\\AI_text_detector\\ai_det\\Lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 207187968 elements. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18833s\u001b[0m 12s/step - accuracy: 0.8592 - loss: 0.3245 - val_accuracy: 0.9550 - val_loss: 0.1141\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21446s\u001b[0m 14s/step - accuracy: 0.9657 - loss: 0.0928 - val_accuracy: 0.9540 - val_loss: 0.1055\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18553s\u001b[0m 12s/step - accuracy: 0.9751 - loss: 0.0666 - val_accuracy: 0.9610 - val_loss: 0.1106\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18557s\u001b[0m 12s/step - accuracy: 0.9781 - loss: 0.0622 - val_accuracy: 0.9640 - val_loss: 0.0989\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18632s\u001b[0m 12s/step - accuracy: 0.9857 - loss: 0.0406 - val_accuracy: 0.9570 - val_loss: 0.1089\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16627s\u001b[0m 11s/step - accuracy: 0.9876 - loss: 0.0402 - val_accuracy: 0.9640 - val_loss: 0.1005\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16143s\u001b[0m 10s/step - accuracy: 0.9924 - loss: 0.0237 - val_accuracy: 0.9570 - val_loss: 0.1297\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15858s\u001b[0m 10s/step - accuracy: 0.9942 - loss: 0.0186 - val_accuracy: 0.9590 - val_loss: 0.1520\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16198s\u001b[0m 10s/step - accuracy: 0.9940 - loss: 0.0181 - val_accuracy: 0.9580 - val_loss: 0.1299\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26810s\u001b[0m 17s/step - accuracy: 0.9954 - loss: 0.0160 - val_accuracy: 0.9540 - val_loss: 0.1888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2c9d79e5f90>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(pad_token_train, lbl_train,validation_data=(pad_token_val, lbl_val), epochs=10, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cnn_50k.keras', overwrite= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving tokenizer\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_det",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
